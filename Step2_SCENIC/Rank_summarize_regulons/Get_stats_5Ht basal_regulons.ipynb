{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86966ef6-24cb-4d52-afe8-2da0ab313e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscenic.utils import load_motifs\n",
    "import pickle\n",
    "import numpy as np\n",
    "from arboreto.utils import load_tf_names\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03bd10-4443-4aee-b80c-c2ff37fb1be0",
   "metadata": {},
   "source": [
    "# Format the regulons and save them as a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555d926-89d0-4f33-b0d9-456a1a06ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the regulons generated by pySCENIC to a dictionary containing TF: {(target:importance....)} \n",
    "def format_regulons(regulon_path,regulon_save_path):\n",
    "    regulons =pickle.load(regulon_path)\n",
    "    reg_dict = {}\n",
    "    for reg in regulons:\n",
    "        reg_dict[reg.name] = {key:np.round(reg.gene2weight[key],decimals=3) for key in reg.gene2weight}\n",
    "    with open(regulon_save_path, \"wb\") as f:\n",
    "        pickle.dump(reg_dict, f)\n",
    "    return\n",
    "\n",
    "#Save the formatted regulons as a txt file\n",
    "def save_as_txt(regulon_path,output_file):\n",
    "    # Open the file for writing\n",
    "    regulon_dict = {}\n",
    "    print(regulon_path)\n",
    "    with open(regulon_path, \"rb\") as f:\n",
    "        regulons =pickle.load(f)\n",
    "    for reg in regulons:\n",
    "        regulon_dict[reg.name] = {key:np.round(reg.gene2weight[key],decimals=3) for key in reg.gene2weight}\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"TF\\tNumber of Target Genes\\tTarget Genes\\n\\n\")\n",
    "        for key, inner_dict in regulon_dict.items():\n",
    "            f.write(f\"{key}\\t{len(inner_dict)}\\t{list(inner_dict.items())}\\n\\n\")\n",
    "\n",
    "for i in range(0,20):\n",
    "    file = f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run{i}.p'\n",
    "    output = f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/Formatted/5ht_basal_regulons_run{i}_formatted.txt'\n",
    "    save_as_txt(file,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98242c16-7301-4d68-a976-9e0d487639a2",
   "metadata": {},
   "source": [
    "# Analyze the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27074cb2-03a5-49be-b762-8ec24063109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_reg_dict(regulon_path):\n",
    "    regulon_dict_without_imp = {}\n",
    "    regulon_dict_with_imp = {}\n",
    "    print(regulon_path)\n",
    "    with open(regulon_path, \"rb\") as f:\n",
    "        regulons =pickle.load(f)\n",
    "    for reg in regulons:\n",
    "        regulon_dict_without_imp[reg.name] = set([key for key in reg.gene2weight])\n",
    "        regulon_dict_with_imp[reg.name] = [(key,np.round(reg.gene2weight[key],decimals=3)) for key in reg.gene2weight]\n",
    "    return regulon_dict_without_imp,regulon_dict_with_imp\n",
    "    \n",
    "# for i in range(0,10):\n",
    "#     f = f'../../results/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run{i}.p'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fae9de-643f-4d7c-b10d-5bf145543c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_0,dict_0_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run0.p')\n",
    "dict_1,dict_1_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run1.p')\n",
    "dict_2,dict_2_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run2.p')\n",
    "dict_3,dict_3_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run3.p')\n",
    "dict_4,dict_4_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run4.p')\n",
    "dict_5,dict_5_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run5.p')\n",
    "dict_6,dict_6_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run6.p')\n",
    "dict_7,dict_7_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run7.p')\n",
    "dict_8,dict_8_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run8.p')\n",
    "dict_9,dict_9_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run9.p')\n",
    "dict_10,dict_10_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run10.p')\n",
    "dict_11,dict_11_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run11.p')\n",
    "dict_12,dict_12_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run12.p')\n",
    "dict_13,dict_13_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run13.p')\n",
    "dict_14,dict_14_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run14.p')\n",
    "dict_15,dict_15_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run15.p')\n",
    "dict_16,dict_16_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run16.p')\n",
    "dict_17,dict_17_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run17.p')\n",
    "dict_18,dict_18_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run18.p')\n",
    "dict_19,dict_19_with_imp = view_reg_dict(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/5ht_basal_regulons_run19.p')\n",
    "dicts = [dict_0,dict_1,dict_2,dict_3,dict_4,dict_5,dict_6,dict_7,dict_8,dict_9,\n",
    "        dict_10,dict_11,dict_12,dict_13,dict_14,dict_15,dict_16,dict_17,dict_18,dict_19]\n",
    "dicts_with_imp = [dict_0_with_imp,dict_1_with_imp,dict_2_with_imp,dict_3_with_imp,\n",
    "                  dict_4_with_imp,dict_5_with_imp,dict_6_with_imp,dict_7_with_imp,dict_8_with_imp,\n",
    "                  dict_9_with_imp,dict_10_with_imp,dict_11_with_imp,dict_12_with_imp,dict_13_with_imp,\n",
    "                  dict_14_with_imp,dict_15_with_imp,dict_16_with_imp,dict_17_with_imp,dict_18_with_imp,\n",
    "                  dict_19_with_imp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b1604",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6ad8e-f4a6-4468-b72f-e01b490ed184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "data = sc.read_h5ad('../../data/combined_data_5ht6hointersection_union_highly_var.h5ad')\n",
    "ht5_data = data[data.obs['orig.ident'] == '5Ht']\n",
    "ht5_basal = ht5_data[ht5_data.obs['cluster1'] == 'Mammary epithelial cells-Basal']\n",
    "tfs = load_tf_names('../../data/allTFs_mm.txt')\n",
    "tfs = sorted(list((set(tfs).intersection(ht5_data.var_names))))\n",
    "tfs = [tf + '(+)' for tf in tfs]\n",
    "target_genes = ht5_basal.var_names\n",
    "cells = ht5_basal.obs_names\n",
    "data = sc.read_h5ad('../../data/combined_data_filtered_5ht6ho_intersection.h5ad')\n",
    "ht5_basal = data[data.obs_names.isin(cells)]\n",
    "ht5_basal = ht5_basal[:,list(target_genes)]\n",
    "sc.pp.log1p(ht5_basal)\n",
    "counts_df_5ht_basal = pd.DataFrame(ht5_basal.X, index=ht5_basal.obs_names,columns=ht5_basal.var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340f74a",
   "metadata": {},
   "source": [
    "# Get statistics for each TF and its target genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the following stats for each TF:\n",
    "1. Frequency of occurence (Number of occurences/total runs)\n",
    "2. Median of importance scores +/- Standard Deviation of importance scores - from positive runs (calculate this based on \n",
    "scores in runs where it actually appears. For example, if gene X appears in 2 out of 20 runs, \n",
    "calculate this statistic using scores in those 2 runs.)\n",
    "3. Median of importance scores +/- Standard Deviation of importance scores - from all runs\n",
    "4. Counts - mean ;  median +/- standard deviation (Log transform the raw data (filtered after removing bad genes and cells)\n",
    "and find the counts from there) - these must be calculated for the specific mouse type and cell type (eg 5ht basal).\n",
    "5. Median of its ranks + standard deviation of its ranks (measured by the importance scores in the descending order) \n",
    "across all runs in which the target gene is present.\n",
    "'''\n",
    "#Loop over all the TFs\n",
    "for tf in tfs:\n",
    "    #Make necessary lists to store the results\n",
    "    all_genes = [] #Will contain all target genes for the current TF across all runs\n",
    "    ranks = [] # Will contain all target genes,importance and ranks across all runs\n",
    "    genes_with_ranks = [] #This is a list of lists. Each list within corresponds to a run. Contains target genes,imp and ranks for the current TF\n",
    "    meds = [] #Will contain stat #2 given above\n",
    "    sds = []\n",
    "    meds_all_runs = [] #Will contain stat #3 given above\n",
    "    sds_all_runs = []\n",
    "    med_ranks = [] #Will contain stat #5 given above\n",
    "    sd_ranks = []\n",
    "    exp_mean = [] #Will contain stat #4 given above\n",
    "    exp_median = [] #Will contain stat #4 given above\n",
    "    sd_exp = []\n",
    "    \n",
    "    #Loop over regulons in different runs\n",
    "    #Get a union of all target genes of the current TF across all runs\n",
    "    for i,d in enumerate(dicts):\n",
    "        if tf in d:\n",
    "            all_genes += list(d[tf])\n",
    "    #Only if this union in non zero, proceed; If zero, the TF is not present in any regulon\n",
    "    if len(all_genes)!= 0:\n",
    "        #Calculate the frequency of the target genes.\n",
    "        # Count the occurrences of each gene\n",
    "        gene_counts = Counter(all_genes)\n",
    "        # Calculate the frequency of each gene based on the formula\n",
    "        n = len(dicts)\n",
    "        gene_frequencies = {gene: count / n for gene, count in gene_counts.items()}\n",
    "\n",
    "        # Create a DataFrame from the gene frequencies dictionary\n",
    "        df = pd.DataFrame(list(gene_frequencies.items()), columns=['Gene', 'Frequency'])\n",
    "        \n",
    "        #Loop over regulons containing importance scores.\n",
    "        for d in dicts_with_imp:\n",
    "            if tf in d:\n",
    "                genes_with_ranks.append(list(d[tf]))\n",
    "        #Get ranks for all target genes, respective to their runs.\n",
    "        for l in genes_with_ranks:\n",
    "            sorted_data = sorted(l, key=lambda x: -x[1])\n",
    "            sorted_data_with_rank = [(item[0], item[1], idx + 1) for idx, item in enumerate(sorted_data)]\n",
    "            ranks += sorted_data_with_rank\n",
    "        #Calculate the statistics for each target gene of the current TF\n",
    "        for gene in df['Gene']:\n",
    "            if gene == 'P4ha1':\n",
    "                print(tf,gene)\n",
    "            curr_imps = []\n",
    "            curr_imps_succ = []\n",
    "            curr_ranks = []\n",
    "            for t in ranks:\n",
    "                #For each target gene, if it is present in the dataframe (containing frequencies), calculate the stats\n",
    "                if t[0] == gene:\n",
    "                    curr_imps.append(t[1])#Save importance\n",
    "                    curr_ranks.append(t[2])#Save ranks\n",
    "\n",
    "            curr_imps_succ += curr_imps\n",
    "            #Add 0 for runs where the current target does not appear\n",
    "            while len(curr_imps_succ)<len(dicts):\n",
    "                curr_imps_succ.append(0)\n",
    "            #Calculate stat #2\n",
    "            median = statistics.median(curr_imps)\n",
    "            std_dev = np.std(curr_imps)\n",
    "            meds.append(np.round(median,3))\n",
    "            sds.append(np.round(std_dev,3))\n",
    "            \n",
    "            #Calculate stat #3\n",
    "            median_all_run = statistics.median(curr_imps_succ)\n",
    "            std_dev_all_run = np.std(curr_imps_succ)\n",
    "            meds_all_runs.append(np.round(median_all_run,3))\n",
    "            sds_all_runs.append(np.round(std_dev_all_run,3))\n",
    "            \n",
    "            #Calculate stat #4\n",
    "            median_exp = statistics.median(counts_df_5ht_basal[gene])\n",
    "            std_dev_exp = np.std(counts_df_5ht_basal[gene])\n",
    "            exp_median.append(np.round(median_exp,3))\n",
    "            sd_exp.append(np.round(std_dev_exp,3))\n",
    "            \n",
    "            #Calculate stat #5\n",
    "            median_ranks = statistics.median(curr_ranks)\n",
    "            std_dev_ranks = np.std(curr_ranks)\n",
    "            med_ranks.append(np.round(median_ranks,3))\n",
    "            sd_ranks.append(np.round(std_dev_ranks,3))\n",
    "            \n",
    "            #code for formatting median to median +/- SD. \n",
    "            #Format the stats\n",
    "\n",
    "            exp_mean.append(np.round(np.mean(counts_df_5ht_basal[gene]),3))\n",
    "        #Add these to the dataframe\n",
    "        df['Median_succ_runs'] = meds  \n",
    "        df['SD_succ_runs'] = sds\n",
    "        df['Median_all_runs'] = meds_all_runs\n",
    "        df['SD_all_runs'] = sds_all_runs\n",
    "        df['Median_ranks'] = med_ranks\n",
    "        df['SD_ranks'] = sd_ranks\n",
    "        df['Mean_expression'] = exp_mean\n",
    "        df['Median_expression'] = exp_median\n",
    "        df['SD_expression'] = sd_exp \n",
    "        \n",
    "        df.sort_values(by='Frequency',ascending=False,inplace=True)\n",
    "        tf_name = tf.split('(')[0]\n",
    "        temp = [tf,0,0,0,0,0,0,0,np.round(np.mean(counts_df_5ht_basal[tf_name]),3),\n",
    "                np.round(np.median(counts_df_5ht_basal[tf_name]),3),np.round(np.std(counts_df_5ht_basal[tf_name]),3)]\n",
    "        temp_df = pd.DataFrame([temp], columns=list(df.columns))\n",
    "        df = pd.concat([temp_df,df])\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #Save the dataframe\n",
    "        df.to_csv(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/Stats/{tf}.csv')\n",
    "    else:#If the TF is not in any regulon in any run, save an empty file.\n",
    "        df = pd.DataFrame()\n",
    "        df.to_csv(f'../../results/results_withP4HA1/results_step_2_strat_1_5ht_basal/Stats/{tf}_empty.csv')\n",
    "#15 TFs have P4HA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4974030",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb3f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
