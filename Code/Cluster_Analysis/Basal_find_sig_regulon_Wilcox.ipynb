{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import ranksums\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee767d4",
   "metadata": {},
   "source": [
    "# Create AUC files with cluster information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54243585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht5_clust_list = {}\n",
    "clusters = ['S1','S2','S3','U1']\n",
    "for c in clusters:\n",
    "    cluster = c\n",
    "    cells = []\n",
    "    with open(f'../../Results/Results_no_ptprc_adgre1/Clusters_Cell_lists/5Ht_Basal_{c}.txt','r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            cells.append(line[0])\n",
    "    f.close()\n",
    "    ht5_clust_list[cluster] = cells\n",
    "ht5_clust_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fce559",
   "metadata": {},
   "outputs": [],
   "source": [
    "ho6_clust_list = {}\n",
    "clusters = ['S1','S2','S3']\n",
    "for c in clusters:\n",
    "    cluster = f'{c}'\n",
    "    cells = []\n",
    "    with open(f'../../Results/Results_no_ptprc_adgre1/Clusters_Cell_lists/6Ho_Basal_{c}.txt','r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            cells.append(line[0])\n",
    "    f.close()\n",
    "    ho6_clust_list[cluster] = cells\n",
    "ho6_clust_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dce76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_5Ht = pd.read_csv('../../Results/Results_no_ptprc_adgre1/Cluster3/gene_cell_corr/Average_linkage/5Ht/Reorder_cells_reg_paper/AUC_mtx_5ht_basal_reord_paper_for_ClusterAnalysis.cdt',sep='\\t')\n",
    "\n",
    "AUC_5Ht = AUC_5Ht.iloc[2:,:]\n",
    "AUC_5Ht = AUC_5Ht.drop(['GID','GWEIGHT'],axis = 1)\n",
    "\n",
    "clusters = []\n",
    "for i,cell in enumerate(AUC_5Ht['Cell']):\n",
    "    for key in ht5_clust_list:\n",
    "        if cell in ht5_clust_list[key]:\n",
    "            clusters.append(key)\n",
    "            \n",
    "AUC_5Ht['NAME'] = clusters\n",
    "\n",
    "AUC_5Ht.rename(columns={'NAME': 'Cluster'}, inplace=True)\n",
    "AUC_5Ht.reset_index(drop=True,inplace=True)\n",
    "\n",
    "AUC_5Ht.to_csv('../../Results/Results_no_ptprc_adgre1/Cluster_Analysis_avg_link_gene_cell_corr/AUC_mtx_with_clusters/5ht_basal_AUC_with_clusts.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c183fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_5Ht['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_6Ho = pd.read_csv('../../Results/Results_no_ptprc_adgre1/Cluster3/gene_cell_corr/Average_linkage/6Ho/Reorder_cells_reg_paper/AUC_mtx_6ho_basal_reord_paper_for_ClusterAnalysis.cdt',sep='\\t')\n",
    "\n",
    "AUC_6Ho = AUC_6Ho.iloc[1:,:]\n",
    "AUC_6Ho = AUC_6Ho.drop(['GID','GWEIGHT'],axis = 1)\n",
    "\n",
    "clusters = []\n",
    "for i,cell in enumerate(AUC_6Ho['Cell']):\n",
    "    for key in ho6_clust_list:\n",
    "        if cell in ho6_clust_list[key]:\n",
    "            clusters.append(key)\n",
    "            \n",
    "AUC_6Ho['NAME'] = clusters\n",
    "\n",
    "AUC_6Ho.rename(columns={'NAME': 'Cluster'}, inplace=True)\n",
    "AUC_6Ho.reset_index(drop=True,inplace=True)\n",
    "\n",
    "AUC_6Ho.to_csv('../../Results/Results_no_ptprc_adgre1/Cluster_Analysis_avg_link_gene_cell_corr/AUC_mtx_with_clusters/6ho_basal_AUC_with_clusts.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8910675",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_6Ho['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678caac3",
   "metadata": {},
   "source": [
    "# Get difference and pvalue -  Taking difference to find FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d210fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_and_filter(dictionary,threshold):\n",
    "    # Sort the dictionary by values\n",
    "    sorted_filtered_dict = {}\n",
    "    for c in dictionary:\n",
    "\n",
    "        sorted_items = sorted(dictionary[c].items(), key=lambda x: x[1][0])\n",
    "\n",
    "        # Create a new dictionary from the sorted items\n",
    "        sorted_dict = {k: v for k, v in sorted_items}\n",
    "\n",
    "         # Create a new dictionary to store filtered key-value pairs\n",
    "        filtered_dict = {}\n",
    "\n",
    "        # Iterate over the items in the input dictionary\n",
    "        for key, value in sorted_items:\n",
    "            # Check if the value is less than x\n",
    "            if value[0] < threshold:\n",
    "                # If the value is less than x, add the key-value pair to the filtered dictionary\n",
    "                filtered_dict[key] = value\n",
    "        sorted_filtered_dict[c] = filtered_dict\n",
    "        dictionary[c] = sorted_dict\n",
    "    return dictionary, sorted_filtered_dict\n",
    "\n",
    "def sort_dict_and_filter_AUC_diff(dictionary,threshold):\n",
    "    # Sort the dictionary by values\n",
    "    sorted_filtered_dict = {}\n",
    "    for c in dictionary:\n",
    "\n",
    "        sorted_items = sorted(dictionary[c].items(), key=lambda x: x[1][0])\n",
    "\n",
    "        # Create a new dictionary from the sorted items\n",
    "        sorted_dict = {k: v for k, v in sorted_items}\n",
    "\n",
    "         # Create a new dictionary to store filtered key-value pairs\n",
    "        filtered_dict = {}\n",
    "\n",
    "        # Iterate over the items in the input dictionary\n",
    "        for key, value in sorted_items:\n",
    "            # Check if the value is less than x\n",
    "            if abs(value[2]) > threshold:\n",
    "                # If the value is less than x, add the key-value pair to the filtered dictionary\n",
    "                filtered_dict[key] = value\n",
    "        sorted_filtered_dict[c] = filtered_dict\n",
    "        dictionary[c] = sorted_dict\n",
    "    return dictionary, sorted_filtered_dict\n",
    "\n",
    "def fdr_adjusted_pvalues(p_values):\n",
    "    \"\"\"\n",
    "    Calculate adjusted p-values correcting for false discovery rate (FDR).\n",
    "\n",
    "    Parameters:\n",
    "        p_values (array-like): List or array of p-values.\n",
    "\n",
    "    Returns:\n",
    "        array-like: Array of adjusted p-values.\n",
    "    \"\"\"\n",
    "    # Perform FDR correction\n",
    "    _, adjusted_p_values, _, _ = multipletests(p_values, method='fdr_bh')#fdr_bh : Benjamini/Hochberg (non-negative)\n",
    "\n",
    "    return adjusted_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667badd8",
   "metadata": {},
   "source": [
    "# Similar Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a13843",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulons = set(AUC_5Ht.columns[2:]).intersection(AUC_6Ho.columns[2:])\n",
    "#regulons_dict = {reg:None for reg in regulons}\n",
    "common_clusts = [1,2,3]\n",
    "all_cluster_stats = {}\n",
    "\n",
    "for i in common_clusts:\n",
    "    current_cluster = f'Cluster_{i}'\n",
    "    all_cluster_stats[current_cluster] = {reg:None for reg in regulons}\n",
    "    \n",
    "    for regulon in all_cluster_stats[current_cluster]:\n",
    "        current_ht5_df = AUC_5Ht[AUC_5Ht['Cell'].isin(ht5_clust_list[f'S{i}'])] \n",
    "        current_ho6_df = AUC_6Ho[AUC_6Ho['Cell'].isin(ho6_clust_list[f'S{i}'])]\n",
    "        ht5_scores = np.array(current_ht5_df[regulon],dtype=float)\n",
    "        ho6_scores = np.array(current_ho6_df[regulon],dtype=float)\n",
    "      \n",
    "        AUC_diff = np.mean(ho6_scores)-np.mean(ht5_scores)\n",
    "        #logfc = np.log2(abs(AUC_diff))\n",
    "        stat,pval = ranksums(ho6_scores,ht5_scores)\n",
    "        all_cluster_stats[current_cluster][regulon] = [pval,AUC_diff,abs(AUC_diff)]\n",
    "    \n",
    "    pvals = [stat[0] for stat in all_cluster_stats[current_cluster].values()]\n",
    "    adjusted_pvals = fdr_adjusted_pvalues(pvals)\n",
    "    for regulon, p_adj in zip(all_cluster_stats[current_cluster].keys(), adjusted_pvals):\n",
    "        all_cluster_stats[current_cluster][regulon][0] = p_adj\n",
    "    \n",
    "all_cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort stats and find significant regulons based on p-value\n",
    "sorted_stats_ori,significant_stats = sort_dict_and_filter(all_cluster_stats,0.05)\n",
    "significant_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort stats and further filter significant regulons based on AUC difference threshold of 0.15\n",
    "sorted_stats,significant_stats_AUC_diff_15 = sort_dict_and_filter_AUC_diff(significant_stats,0.15)\n",
    "significant_stats_AUC_diff_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../../Results/Results_no_ptprc_adgre1/Cluster_Analysis_avg_link_gene_cell_corr/Sig_Regulons'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "for c in significant_stats:\n",
    "    curr_c = 'Cluster_S' + c.split('_')[-1]\n",
    "    curr_reg_dict = sorted_stats_ori[c]\n",
    "    curr_reg_significant_dict = significant_stats[c]\n",
    "    curr_reg_sig_AUC_diff_15_dict = significant_stats_AUC_diff_15[c]\n",
    "    \n",
    "    # Sorted results file\n",
    "    filename = f'{results_dir}/{curr_c}_basal_reg_wilcoxon_AUC_diff_sorted.csv'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Regulon,P_adj,AUC_diff(6ho-5ht),Abs_AUC_diff\\n\")\n",
    "        for key, value in curr_reg_dict.items():\n",
    "            f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")\n",
    "    \n",
    "    # Significant results file\n",
    "    filename = f'{results_dir}/{curr_c}_basal_reg_wilcoxon_AUC_diff_sig.csv'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Regulon,P_adj,AUC_diff(6ho-5ht),Abs_AUC_diff\\n\")\n",
    "        for key, value in curr_reg_significant_dict.items():\n",
    "            f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")\n",
    "    \n",
    "    # 25% significant results file\n",
    "    filename = f'{results_dir}/{curr_c}_basal_reg_wilcoxon_AUC_diff_15_sig.csv'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Regulon,P_adj,AUC_diff(6ho-5ht),Abs_AUC_diff\\n\")\n",
    "        for key, value in curr_reg_sig_AUC_diff_15_dict.items():\n",
    "            f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda3479",
   "metadata": {},
   "source": [
    "# Unique Cluster - U1_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be331bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regulons_dict = {reg:None for reg in regulons}\n",
    "unique_cluster_stats = {}\n",
    "\n",
    "\n",
    "# current_cluster = f'Cluster_{i}'\n",
    "\n",
    "unique_cluster_stats = {reg:None for reg in regulons}\n",
    "for regulon in unique_cluster_stats:\n",
    "    current_u1_wt_df = AUC_5Ht[AUC_5Ht['Cell'].isin(ht5_clust_list['U1'])] \n",
    "    current_other_5ht_clust_df = AUC_5Ht[~AUC_5Ht['Cell'].isin(ht5_clust_list['U1'])]\n",
    "    u1_wt_scores = np.array(current_u1_wt_df[regulon],dtype=float)\n",
    "    other_5ht_scores = np.array(current_other_5ht_clust_df[regulon],dtype=float)\n",
    "\n",
    "    AUC_diff = np.mean(u1_wt_scores)-np.mean(other_5ht_scores)\n",
    "    #logfc = np.log2(abs(AUC_diff))\n",
    "    stat,pval = ranksums(u1_wt_scores, other_5ht_scores)\n",
    "    unique_cluster_stats[regulon] = [pval,AUC_diff,abs(AUC_diff)]\n",
    "\n",
    "unique_cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust for FDR - BH correction\n",
    "pvals = [stat[0] for stat in unique_cluster_stats.values()]\n",
    "adjusted_pvals = fdr_adjusted_pvalues(pvals)\n",
    "for regulon, p_adj in zip(unique_cluster_stats.keys(), adjusted_pvals):\n",
    "    unique_cluster_stats[regulon][0] = p_adj\n",
    "    \n",
    "unique_cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1327de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to sort\n",
    "def sort_dict_and_filter_unique(dictionary, threshold):\n",
    "    # Sort the dictionary by the first element of the list in values\n",
    "    sorted_items = sorted(dictionary.items(), key=lambda x: x[1][0])\n",
    "\n",
    "    # Create a new dictionary from the sorted items\n",
    "    sorted_dict = {k: v for k, v in sorted_items}\n",
    "\n",
    "    # Create a new dictionary to store filtered key-value pairs\n",
    "    filtered_dict = {}\n",
    "\n",
    "    # Iterate over the items in the sorted dictionary\n",
    "    for key, value in sorted_items:\n",
    "        # Check if the first element of the value (list) is less than the threshold\n",
    "        if value[0] < threshold:\n",
    "            filtered_dict[key] = value\n",
    "\n",
    "    return sorted_dict, filtered_dict\n",
    "\n",
    "\n",
    "def sort_dict_and_filter_AUC_diff(dictionary, threshold):\n",
    "    # Sort the dictionary by the first element of the list in values\n",
    "    sorted_items = sorted(dictionary.items(), key=lambda x: x[1][0])\n",
    "\n",
    "    # Create a new dictionary from the sorted items\n",
    "    sorted_dict = {k: v for k, v in sorted_items}\n",
    "\n",
    "    # Create a new dictionary to store filtered key-value pairs\n",
    "    filtered_dict = {}\n",
    "\n",
    "    # Iterate over the items in the sorted dictionary\n",
    "    for key, value in sorted_items:\n",
    "        # Check if the absolute value of the third element is greater than the threshold\n",
    "        if abs(value[2]) > threshold:\n",
    "            filtered_dict[key] = value\n",
    "\n",
    "    return sorted_dict, filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf133fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get significant regulons based on p-value (<0.05)\n",
    "sorted_unique, filtered_pval_u1_wt = sort_dict_and_filter_unique(unique_cluster_stats, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter significant regulons based on AUC difference threshold\n",
    "_,filtered_pval_AUC_diff_u1_wt = sort_dict_and_filter_AUC_diff(filtered_pval_u1_wt, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11875d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_pval_AUC_diff_u1_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results\n",
    "filename = f'{results_dir}/U1_wt_basal_reg_wilcoxon_AUC_diff_sorted.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"Regulon,P_adj,AUC_diff(U1 - other 5ht),Abs_AUC_diff\\n\")\n",
    "    for key, value in sorted_unique.items():\n",
    "        f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")\n",
    "\n",
    "# Significant results file\n",
    "filename = f'{results_dir}/U1_wt_basal_reg_wilcoxon_AUC_diff_sig.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"Regulon,P_adj,AUC_diff(U1 - other 5ht),Abs_AUC_diff\\n\")\n",
    "    for key, value in filtered_pval_u1_wt.items():\n",
    "        f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")\n",
    "        \n",
    "filename = f'{results_dir}/U1_wt_basal_reg_wilcoxon_AUC_diff_15_sig.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(f\"Regulon,P_adj,AUC_diff(U1 - other 5ht),Abs_AUC_diff\\n\")\n",
    "    for key, value in filtered_pval_AUC_diff_u1_wt.items():\n",
    "        f.write(f\"{key},{value[0]},{value[1]},{value[2]}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b68bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936bcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ee51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
