{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0258d2-0e15-4f0f-b591-0726e58b9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from arboreto.utils import load_tf_names\n",
    "from arboreto.algo import grnboost2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5a530-835c-4e60-8977-147d3af9e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "data = sc.read_h5ad('../../Processed_Data/NetworkData_HVGs_basal_5ht6ho_without_PTPRC_Adgre1.h5ad')#Change path as required.\n",
    "\n",
    "#Subset the data for 6Ho\n",
    "ho6_data = data[data.obs['orig.ident'] == '6Ho']\n",
    "\n",
    "#Load the TFs\n",
    "tfs = load_tf_names('../../Processed_Data/allTFs_mm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c2b76-3070-4476-b1fa-3589fceae248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the expression data\n",
    "counts_df_6ho_basal = pd.DataFrame(ho6_data.X, index=ho6_data.obs_names,columns=ho6_data.var_names)\n",
    "\n",
    "#Get the TFs that are in the data\n",
    "tfs = sorted(list((set(tfs).intersection(ho6_data.var_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050461c-6318-4ded-bdcd-3e820fbce156",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d47a3",
   "metadata": {},
   "source": [
    "# RUN GRNBOOST2 for all TFs but in batches of 10 TFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2f523-d9a1-43df-9167-70413197fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grnboost2 with SGBM parameters, without a seed - 6ho_basal\n",
    "for i in range(0,20):#This will run the loop 20 times:\n",
    "    print(f'Run: {i}')\n",
    "    #Run GRNBOOST2 for batches of 10 TFs.\n",
    "    #Create a variable that will contain the entire edge list\n",
    "    adjacencies = None\n",
    "    index = 0\n",
    "    iterations = np.floor(len(tfs)/10)\n",
    "    n = 10\n",
    "    count = 0\n",
    "    #Run in batches of 10\n",
    "    while count < iterations + 1:\n",
    "        \n",
    "        curr_tfs = tfs[index:index+n]\n",
    "        curr_adjacencies = grnboost2(counts_df_6ho_basal, tf_names=curr_tfs, verbose=False)\n",
    "        \n",
    "        if adjacencies is None:\n",
    "            adjacencies = curr_adjacencies\n",
    "        else:\n",
    "            adjacencies = pd.concat([adjacencies, curr_adjacencies], axis=0)\n",
    "        index += 10\n",
    "        count += 1\n",
    "        if count == iterations:\n",
    "            n = int(len(tfs) - iterations*n)\n",
    "        print(f'Done for {count*10} TFs')\n",
    "        ##Save results for every 100 TFs if needed\n",
    "        # if count%10 == 0:\n",
    "        #     adjacencies.to_csv(f'../../results/results_step_1_grnboost2_6ho_basal/6Ho_basal_adjacencies_run{i}_{count*10}TFs.csv')\n",
    "    adjacencies.to_csv(f'../../Results/Results_no_ptprc_adgre1/SCENIC_results/results_step1_6ho_basal/6Ho_basal_adjacencies_run{i}_allTFs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faecfa4-c7be-4340-a515-ac09aaa6d255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
